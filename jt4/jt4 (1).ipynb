{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flaml[notebook,ts_forecast]"
      ],
      "metadata": {
        "id": "k2bLP3Vtst1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mteqxzpYscab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oiW6C7bDscae"
      },
      "outputs": [],
      "source": [
        "#use plotly for pandas backend\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "import plotly.io as pio\n",
        "pio.renderers\n",
        "pio.renderers.default = \"notebook\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BEvsesZFscae"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('train_IxoE5JN.csv')\n",
        "df = df.bfill().ffill()\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "df = df.drop(['row_id'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nujzmwliscaf"
      },
      "outputs": [],
      "source": [
        "data=df[['datetime','energy']]\n",
        "num_samples = data.shape[0]\n",
        "time_horizon = 100\n",
        "split_idx = num_samples - time_horizon\n",
        "# train_df is a dataframe with two columns: timestamp and label\n",
        "train_df = data[:split_idx]\n",
        "# X_test is a dataframe with dates for prediction\n",
        "X_test = data[split_idx:]['datetime'].to_frame()\n",
        "y_test = data[split_idx:]['energy']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2ZafaC74scas"
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LPXuemMsscat"
      },
      "outputs": [],
      "source": [
        "settings = {\n",
        "    \"time_budget\": 240,  # total running time in seconds\n",
        "    # primary metric for validation: 'mape' is generally used for forecast tasks\n",
        "    \"metric\": 'mape',\n",
        "    \"task\": 'ts_forecast',  # task type\n",
        "    # \"log_file_name\": 'CO2_forecast.log',  # flaml log file\n",
        "    # validation method can be chosen from ['auto', 'holdout', 'cv']\n",
        "    \"eval_method\": \"holdout\",\n",
        "    \"seed\": 7654321,  # random seed\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImbNfXZ8scat",
        "outputId": "a4e883ad-06e4-4e84-88aa-c04fec332f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 11-18 07:46:20] {2599} INFO - task = ts_forecast\n",
            "INFO:flaml.automl:task = ts_forecast\n",
            "[flaml.automl: 11-18 07:46:20] {2601} INFO - Data split method: time\n",
            "INFO:flaml.automl:Data split method: time\n",
            "[flaml.automl: 11-18 07:46:20] {2604} INFO - Evaluation method: holdout\n",
            "INFO:flaml.automl:Evaluation method: holdout\n",
            "[flaml.automl: 11-18 07:46:20] {2726} INFO - Minimizing error metric: mape\n",
            "INFO:flaml.automl:Minimizing error metric: mape\n",
            "[flaml.automl: 11-18 07:46:20] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'prophet', 'arima', 'sarimax']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'prophet', 'arima', 'sarimax']\n",
            "[flaml.automl: 11-18 07:46:20] {3166} INFO - iteration 0, current learner lgbm\n",
            "INFO:flaml.automl:iteration 0, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:21] {3297} INFO - Estimated sufficient time budget=84993s. Estimated necessary time budget=85s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=84993s. Estimated necessary time budget=85s.\n",
            "[flaml.automl: 11-18 07:46:21] {3349} INFO -  at 1.2s,\testimator lgbm's best error=0.3923,\tbest estimator lgbm's best error=0.3923\n",
            "INFO:flaml.automl: at 1.2s,\testimator lgbm's best error=0.3923,\tbest estimator lgbm's best error=0.3923\n",
            "[flaml.automl: 11-18 07:46:21] {3166} INFO - iteration 1, current learner lgbm\n",
            "INFO:flaml.automl:iteration 1, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:21] {3349} INFO -  at 1.5s,\testimator lgbm's best error=0.3908,\tbest estimator lgbm's best error=0.3908\n",
            "INFO:flaml.automl: at 1.5s,\testimator lgbm's best error=0.3908,\tbest estimator lgbm's best error=0.3908\n",
            "[flaml.automl: 11-18 07:46:21] {3166} INFO - iteration 2, current learner lgbm\n",
            "INFO:flaml.automl:iteration 2, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:21] {3349} INFO -  at 1.5s,\testimator lgbm's best error=0.3908,\tbest estimator lgbm's best error=0.3908\n",
            "INFO:flaml.automl: at 1.5s,\testimator lgbm's best error=0.3908,\tbest estimator lgbm's best error=0.3908\n",
            "[flaml.automl: 11-18 07:46:21] {3166} INFO - iteration 3, current learner lgbm\n",
            "INFO:flaml.automl:iteration 3, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:21] {3349} INFO -  at 1.7s,\testimator lgbm's best error=0.3908,\tbest estimator lgbm's best error=0.3908\n",
            "INFO:flaml.automl: at 1.7s,\testimator lgbm's best error=0.3908,\tbest estimator lgbm's best error=0.3908\n",
            "[flaml.automl: 11-18 07:46:21] {3166} INFO - iteration 4, current learner lgbm\n",
            "INFO:flaml.automl:iteration 4, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:22] {3349} INFO -  at 1.9s,\testimator lgbm's best error=0.3873,\tbest estimator lgbm's best error=0.3873\n",
            "INFO:flaml.automl: at 1.9s,\testimator lgbm's best error=0.3873,\tbest estimator lgbm's best error=0.3873\n",
            "[flaml.automl: 11-18 07:46:22] {3166} INFO - iteration 5, current learner lgbm\n",
            "INFO:flaml.automl:iteration 5, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:22] {3349} INFO -  at 2.2s,\testimator lgbm's best error=0.3868,\tbest estimator lgbm's best error=0.3868\n",
            "INFO:flaml.automl: at 2.2s,\testimator lgbm's best error=0.3868,\tbest estimator lgbm's best error=0.3868\n",
            "[flaml.automl: 11-18 07:46:22] {3166} INFO - iteration 6, current learner lgbm\n",
            "INFO:flaml.automl:iteration 6, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:22] {3349} INFO -  at 2.3s,\testimator lgbm's best error=0.3868,\tbest estimator lgbm's best error=0.3868\n",
            "INFO:flaml.automl: at 2.3s,\testimator lgbm's best error=0.3868,\tbest estimator lgbm's best error=0.3868\n",
            "[flaml.automl: 11-18 07:46:22] {3166} INFO - iteration 7, current learner lgbm\n",
            "INFO:flaml.automl:iteration 7, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:23] {3349} INFO -  at 2.8s,\testimator lgbm's best error=0.3809,\tbest estimator lgbm's best error=0.3809\n",
            "INFO:flaml.automl: at 2.8s,\testimator lgbm's best error=0.3809,\tbest estimator lgbm's best error=0.3809\n",
            "[flaml.automl: 11-18 07:46:23] {3166} INFO - iteration 8, current learner lgbm\n",
            "INFO:flaml.automl:iteration 8, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:23] {3349} INFO -  at 3.1s,\testimator lgbm's best error=0.3809,\tbest estimator lgbm's best error=0.3809\n",
            "INFO:flaml.automl: at 3.1s,\testimator lgbm's best error=0.3809,\tbest estimator lgbm's best error=0.3809\n",
            "[flaml.automl: 11-18 07:46:23] {3166} INFO - iteration 9, current learner lgbm\n",
            "INFO:flaml.automl:iteration 9, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:23] {3349} INFO -  at 3.3s,\testimator lgbm's best error=0.3809,\tbest estimator lgbm's best error=0.3809\n",
            "INFO:flaml.automl: at 3.3s,\testimator lgbm's best error=0.3809,\tbest estimator lgbm's best error=0.3809\n",
            "[flaml.automl: 11-18 07:46:23] {3166} INFO - iteration 10, current learner lgbm\n",
            "INFO:flaml.automl:iteration 10, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:24] {3349} INFO -  at 4.6s,\testimator lgbm's best error=0.3650,\tbest estimator lgbm's best error=0.3650\n",
            "INFO:flaml.automl: at 4.6s,\testimator lgbm's best error=0.3650,\tbest estimator lgbm's best error=0.3650\n",
            "[flaml.automl: 11-18 07:46:24] {3166} INFO - iteration 11, current learner rf\n",
            "INFO:flaml.automl:iteration 11, current learner rf\n",
            "[flaml.automl: 11-18 07:46:25] {3349} INFO -  at 4.9s,\testimator rf's best error=0.3906,\tbest estimator lgbm's best error=0.3650\n",
            "INFO:flaml.automl: at 4.9s,\testimator rf's best error=0.3906,\tbest estimator lgbm's best error=0.3650\n",
            "[flaml.automl: 11-18 07:46:25] {3166} INFO - iteration 12, current learner rf\n",
            "INFO:flaml.automl:iteration 12, current learner rf\n",
            "[flaml.automl: 11-18 07:46:25] {3349} INFO -  at 5.1s,\testimator rf's best error=0.3895,\tbest estimator lgbm's best error=0.3650\n",
            "INFO:flaml.automl: at 5.1s,\testimator rf's best error=0.3895,\tbest estimator lgbm's best error=0.3650\n",
            "[flaml.automl: 11-18 07:46:25] {3166} INFO - iteration 13, current learner xgboost\n",
            "INFO:flaml.automl:iteration 13, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:25] {3349} INFO -  at 5.3s,\testimator xgboost's best error=0.7905,\tbest estimator lgbm's best error=0.3650\n",
            "INFO:flaml.automl: at 5.3s,\testimator xgboost's best error=0.7905,\tbest estimator lgbm's best error=0.3650\n",
            "[flaml.automl: 11-18 07:46:25] {3166} INFO - iteration 14, current learner xgboost\n",
            "INFO:flaml.automl:iteration 14, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:25] {3349} INFO -  at 5.4s,\testimator xgboost's best error=0.7905,\tbest estimator lgbm's best error=0.3650\n",
            "INFO:flaml.automl: at 5.4s,\testimator xgboost's best error=0.7905,\tbest estimator lgbm's best error=0.3650\n",
            "[flaml.automl: 11-18 07:46:25] {3166} INFO - iteration 15, current learner xgboost\n",
            "INFO:flaml.automl:iteration 15, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:25] {3349} INFO -  at 5.4s,\testimator xgboost's best error=0.4122,\tbest estimator lgbm's best error=0.3650\n",
            "INFO:flaml.automl: at 5.4s,\testimator xgboost's best error=0.4122,\tbest estimator lgbm's best error=0.3650\n",
            "[flaml.automl: 11-18 07:46:25] {3166} INFO - iteration 16, current learner xgboost\n",
            "INFO:flaml.automl:iteration 16, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:26] {3349} INFO -  at 5.8s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3650\n",
            "INFO:flaml.automl: at 5.8s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3650\n",
            "[flaml.automl: 11-18 07:46:26] {3166} INFO - iteration 17, current learner lgbm\n",
            "INFO:flaml.automl:iteration 17, current learner lgbm\n",
            "[flaml.automl: 11-18 07:46:30] {3349} INFO -  at 9.8s,\testimator lgbm's best error=0.3639,\tbest estimator lgbm's best error=0.3639\n",
            "INFO:flaml.automl: at 9.8s,\testimator lgbm's best error=0.3639,\tbest estimator lgbm's best error=0.3639\n",
            "[flaml.automl: 11-18 07:46:30] {3166} INFO - iteration 18, current learner xgboost\n",
            "INFO:flaml.automl:iteration 18, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:30] {3349} INFO -  at 9.9s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "INFO:flaml.automl: at 9.9s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "[flaml.automl: 11-18 07:46:30] {3166} INFO - iteration 19, current learner xgboost\n",
            "INFO:flaml.automl:iteration 19, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:30] {3349} INFO -  at 10.1s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "INFO:flaml.automl: at 10.1s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "[flaml.automl: 11-18 07:46:30] {3166} INFO - iteration 20, current learner xgboost\n",
            "INFO:flaml.automl:iteration 20, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:31] {3349} INFO -  at 10.9s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "INFO:flaml.automl: at 10.9s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "[flaml.automl: 11-18 07:46:31] {3166} INFO - iteration 21, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 21, current learner extra_tree\n",
            "[flaml.automl: 11-18 07:46:31] {3349} INFO -  at 11.1s,\testimator extra_tree's best error=0.3929,\tbest estimator lgbm's best error=0.3639\n",
            "INFO:flaml.automl: at 11.1s,\testimator extra_tree's best error=0.3929,\tbest estimator lgbm's best error=0.3639\n",
            "[flaml.automl: 11-18 07:46:31] {3166} INFO - iteration 22, current learner xgboost\n",
            "INFO:flaml.automl:iteration 22, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:31] {3349} INFO -  at 11.3s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "INFO:flaml.automl: at 11.3s,\testimator xgboost's best error=0.3716,\tbest estimator lgbm's best error=0.3639\n",
            "[flaml.automl: 11-18 07:46:31] {3166} INFO - iteration 23, current learner xgboost\n",
            "INFO:flaml.automl:iteration 23, current learner xgboost\n",
            "[flaml.automl: 11-18 07:46:34] {3349} INFO -  at 14.0s,\testimator xgboost's best error=0.3580,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 14.0s,\testimator xgboost's best error=0.3580,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:46:34] {3166} INFO - iteration 24, current learner extra_tree\n",
            "INFO:flaml.automl:iteration 24, current learner extra_tree\n",
            "[flaml.automl: 11-18 07:46:34] {3349} INFO -  at 14.2s,\testimator extra_tree's best error=0.3899,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 14.2s,\testimator extra_tree's best error=0.3899,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:46:34] {3166} INFO - iteration 25, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 25, current learner xgb_limitdepth\n",
            "[flaml.automl: 11-18 07:46:34] {3349} INFO -  at 14.4s,\testimator xgb_limitdepth's best error=0.4031,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 14.4s,\testimator xgb_limitdepth's best error=0.4031,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:46:34] {3166} INFO - iteration 26, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 26, current learner xgb_limitdepth\n",
            "[flaml.automl: 11-18 07:46:34] {3349} INFO -  at 14.4s,\testimator xgb_limitdepth's best error=0.4031,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 14.4s,\testimator xgb_limitdepth's best error=0.4031,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:46:34] {3166} INFO - iteration 27, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 27, current learner xgb_limitdepth\n",
            "[flaml.automl: 11-18 07:46:35] {3349} INFO -  at 15.1s,\testimator xgb_limitdepth's best error=0.3774,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 15.1s,\testimator xgb_limitdepth's best error=0.3774,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:46:35] {3166} INFO - iteration 28, current learner prophet\n",
            "INFO:flaml.automl:iteration 28, current learner prophet\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphly9ifxm/ujsfp55z.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphly9ifxm/x61dv5uy.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=69666', 'data', 'file=/tmp/tmphly9ifxm/ujsfp55z.json', 'init=/tmp/tmphly9ifxm/x61dv5uy.json', 'output', 'file=/tmp/tmpt7yp1fy9/prophet_model-20221118074636.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "07:46:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "07:46:42 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "[flaml.automl: 11-18 07:46:45] {3349} INFO -  at 25.7s,\testimator prophet's best error=2.4631,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 25.7s,\testimator prophet's best error=2.4631,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:46:45] {3166} INFO - iteration 29, current learner arima\n",
            "INFO:flaml.automl:iteration 29, current learner arima\n",
            "[flaml.automl: 11-18 07:46:52] {3349} INFO -  at 32.5s,\testimator arima's best error=1.3886,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 32.5s,\testimator arima's best error=1.3886,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:46:52] {3166} INFO - iteration 30, current learner sarimax\n",
            "INFO:flaml.automl:iteration 30, current learner sarimax\n",
            "[flaml.automl: 11-18 07:48:03] {3349} INFO -  at 103.0s,\testimator sarimax's best error=2627.9305,\tbest estimator xgboost's best error=0.3580\n",
            "INFO:flaml.automl: at 103.0s,\testimator sarimax's best error=2627.9305,\tbest estimator xgboost's best error=0.3580\n",
            "[flaml.automl: 11-18 07:48:03] {3166} INFO - iteration 31, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 31, current learner xgb_limitdepth\n",
            "[flaml.automl: 11-18 07:48:08] {3349} INFO -  at 108.0s,\testimator xgb_limitdepth's best error=0.3432,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "INFO:flaml.automl: at 108.0s,\testimator xgb_limitdepth's best error=0.3432,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "[flaml.automl: 11-18 07:48:08] {3166} INFO - iteration 32, current learner arima\n",
            "INFO:flaml.automl:iteration 32, current learner arima\n",
            "[flaml.automl: 11-18 07:48:10] {3349} INFO -  at 110.4s,\testimator arima's best error=1.3886,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "INFO:flaml.automl: at 110.4s,\testimator arima's best error=1.3886,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "[flaml.automl: 11-18 07:48:10] {3166} INFO - iteration 33, current learner arima\n",
            "INFO:flaml.automl:iteration 33, current learner arima\n",
            "[flaml.automl: 11-18 07:48:27] {3349} INFO -  at 127.1s,\testimator arima's best error=0.9515,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "INFO:flaml.automl: at 127.1s,\testimator arima's best error=0.9515,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "[flaml.automl: 11-18 07:48:27] {3166} INFO - iteration 34, current learner rf\n",
            "INFO:flaml.automl:iteration 34, current learner rf\n",
            "[flaml.automl: 11-18 07:48:27] {3349} INFO -  at 127.7s,\testimator rf's best error=0.3717,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "INFO:flaml.automl: at 127.7s,\testimator rf's best error=0.3717,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "[flaml.automl: 11-18 07:48:27] {3166} INFO - iteration 35, current learner rf\n",
            "INFO:flaml.automl:iteration 35, current learner rf\n",
            "[flaml.automl: 11-18 07:48:30] {3349} INFO -  at 130.2s,\testimator rf's best error=0.3717,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "INFO:flaml.automl: at 130.2s,\testimator rf's best error=0.3717,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "[flaml.automl: 11-18 07:48:30] {3166} INFO - iteration 36, current learner xgboost\n",
            "INFO:flaml.automl:iteration 36, current learner xgboost\n",
            "[flaml.automl: 11-18 07:48:31] {3349} INFO -  at 131.2s,\testimator xgboost's best error=0.3580,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "INFO:flaml.automl: at 131.2s,\testimator xgboost's best error=0.3580,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "[flaml.automl: 11-18 07:48:31] {3166} INFO - iteration 37, current learner prophet\n",
            "INFO:flaml.automl:iteration 37, current learner prophet\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphly9ifxm/drjo8_3j.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphly9ifxm/g1jn49j0.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=40518', 'data', 'file=/tmp/tmphly9ifxm/drjo8_3j.json', 'init=/tmp/tmphly9ifxm/g1jn49j0.json', 'output', 'file=/tmp/tmpelix91hu/prophet_model-20221118074831.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "07:48:31 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "07:48:34 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "[flaml.automl: 11-18 07:48:38] {3349} INFO -  at 138.1s,\testimator prophet's best error=2.4631,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "INFO:flaml.automl: at 138.1s,\testimator prophet's best error=2.4631,\tbest estimator xgb_limitdepth's best error=0.3432\n",
            "[flaml.automl: 11-18 07:48:38] {3166} INFO - iteration 38, current learner rf\n",
            "INFO:flaml.automl:iteration 38, current learner rf\n",
            "[flaml.automl: 11-18 07:48:42] {3349} INFO -  at 142.7s,\testimator rf's best error=0.1499,\tbest estimator rf's best error=0.1499\n",
            "INFO:flaml.automl: at 142.7s,\testimator rf's best error=0.1499,\tbest estimator rf's best error=0.1499\n",
            "[flaml.automl: 11-18 07:48:42] {3166} INFO - iteration 39, current learner rf\n",
            "INFO:flaml.automl:iteration 39, current learner rf\n",
            "[flaml.automl: 11-18 07:49:01] {3349} INFO -  at 161.3s,\testimator rf's best error=0.1099,\tbest estimator rf's best error=0.1099\n",
            "INFO:flaml.automl: at 161.3s,\testimator rf's best error=0.1099,\tbest estimator rf's best error=0.1099\n",
            "[flaml.automl: 11-18 07:49:01] {3166} INFO - iteration 40, current learner sarimax\n",
            "INFO:flaml.automl:iteration 40, current learner sarimax\n",
            "[flaml.automl: 11-18 07:49:13] {3349} INFO -  at 173.5s,\testimator sarimax's best error=1224.4980,\tbest estimator rf's best error=0.1099\n",
            "INFO:flaml.automl: at 173.5s,\testimator sarimax's best error=1224.4980,\tbest estimator rf's best error=0.1099\n",
            "[flaml.automl: 11-18 07:49:13] {3166} INFO - iteration 41, current learner prophet\n",
            "INFO:flaml.automl:iteration 41, current learner prophet\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphly9ifxm/5z8jw2en.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphly9ifxm/j0t5z3f3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.7/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=7298', 'data', 'file=/tmp/tmphly9ifxm/5z8jw2en.json', 'init=/tmp/tmphly9ifxm/j0t5z3f3.json', 'output', 'file=/tmp/tmp0l46y5vg/prophet_model-20221118074914.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "07:49:14 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "07:49:20 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "[flaml.automl: 11-18 07:49:24] {3349} INFO -  at 184.0s,\testimator prophet's best error=2.4631,\tbest estimator rf's best error=0.1099\n",
            "INFO:flaml.automl: at 184.0s,\testimator prophet's best error=2.4631,\tbest estimator rf's best error=0.1099\n",
            "[flaml.automl: 11-18 07:49:24] {3166} INFO - iteration 42, current learner arima\n",
            "INFO:flaml.automl:iteration 42, current learner arima\n",
            "[flaml.automl: 11-18 07:49:31] {3349} INFO -  at 191.1s,\testimator arima's best error=0.4081,\tbest estimator rf's best error=0.1099\n",
            "INFO:flaml.automl: at 191.1s,\testimator arima's best error=0.4081,\tbest estimator rf's best error=0.1099\n",
            "[flaml.automl: 11-18 07:49:31] {3166} INFO - iteration 43, current learner xgb_limitdepth\n",
            "INFO:flaml.automl:iteration 43, current learner xgb_limitdepth\n",
            "[flaml.automl: 11-18 07:49:31] {3349} INFO -  at 191.6s,\testimator xgb_limitdepth's best error=0.3432,\tbest estimator rf's best error=0.1099\n",
            "INFO:flaml.automl: at 191.6s,\testimator xgb_limitdepth's best error=0.3432,\tbest estimator rf's best error=0.1099\n",
            "[flaml.automl: 11-18 07:49:31] {3166} INFO - iteration 44, current learner arima\n",
            "INFO:flaml.automl:iteration 44, current learner arima\n",
            "[flaml.automl: 11-18 07:49:47] {3349} INFO -  at 207.5s,\testimator arima's best error=0.4081,\tbest estimator rf's best error=0.1099\n",
            "INFO:flaml.automl: at 207.5s,\testimator arima's best error=0.4081,\tbest estimator rf's best error=0.1099\n",
            "[flaml.automl: 11-18 07:49:47] {3166} INFO - iteration 45, current learner sarimax\n",
            "INFO:flaml.automl:iteration 45, current learner sarimax\n",
            "[flaml.automl: 11-18 07:50:49] {3349} INFO -  at 269.2s,\testimator sarimax's best error=1.4260,\tbest estimator rf's best error=0.1099\n",
            "INFO:flaml.automl: at 269.2s,\testimator sarimax's best error=1.4260,\tbest estimator rf's best error=0.1099\n",
            "[flaml.automl: 11-18 07:51:10] {3604} INFO - retrain rf for 20.8s\n",
            "INFO:flaml.automl:retrain rf for 20.8s\n",
            "[flaml.automl: 11-18 07:51:10] {3609} INFO - retrained model: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',\n",
            "                      max_depth=None, max_features=1.0, max_leaf_nodes=13,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_samples_leaf=1, min_samples_split=2,\n",
            "                      min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
            "                      oob_score=False, random_state=None, verbose=0,\n",
            "                      warm_start=False)\n",
            "INFO:flaml.automl:retrained model: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',\n",
            "                      max_depth=None, max_features=1.0, max_leaf_nodes=13,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_samples_leaf=1, min_samples_split=2,\n",
            "                      min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
            "                      oob_score=False, random_state=None, verbose=0,\n",
            "                      warm_start=False)\n",
            "[flaml.automl: 11-18 07:51:10] {2901} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 11-18 07:51:10] {2903} INFO - Time taken to find the best model: 161.3149516582489\n",
            "INFO:flaml.automl:Time taken to find the best model: 161.3149516582489\n"
          ]
        }
      ],
      "source": [
        "'''The main flaml automl API'''\n",
        "automl.fit(dataframe=train_df,  # training data\n",
        "           label='energy',  # label column\n",
        "           period=time_horizon,  # key word argument 'period' must be included for forecast task)\n",
        "           **settings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSFYaRCYscat",
        "outputId": "b97852ec-954e-4acb-a759-5b9c2f81a20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: rf\n",
            "Best hyperparmeter config: {'n_estimators': 10, 'max_features': 1.0, 'max_leaves': 13, 'optimize_for_horizon': False, 'lags': 64, 'FLAML_sample_size': 94792}\n",
            "Best mape on validation data: 0.10987484425193735\n",
            "Training duration of best run: 20.847909688949585s\n"
          ]
        }
      ],
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print(f'Best mape on validation data: {automl.best_loss}')\n",
        "print(f'Training duration of best run: {automl.best_config_train_time}s')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('automl.pkl', 'wb') as f:\n",
        "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "XFVX1CTxuK8b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flaml_y_pred = automl.predict(X_test)\n",
        "print(f\"Predicted labels\\n{flaml_y_pred}\")\n",
        "print(f\"True labels\\n{y_test}\")"
      ],
      "metadata": {
        "id": "iH0YeTrvuRcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('mape', '=', sklearn_metric_loss_score('mape', y_true=y_test, y_predict=flaml_y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWQwD362uVH3",
        "outputId": "6a7db202-542c-4d68-d3d7-f2ba7ae893ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mape = 0.09217681202274092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rms = mean_squared_error(y_test, flaml_y_pred, squared=False)"
      ],
      "metadata": {
        "id": "AT4f9myfuap1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoMpKUaFukcW",
        "outputId": "db456ed6-c5cb-4477-83e7-ade174780bce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "247.34025245518433"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv('/content/test_WudNWDM.csv')"
      ],
      "metadata": {
        "id": "GPx4su9FulO4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test=test.drop(['row_id'], axis=1)"
      ],
      "metadata": {
        "id": "ezllcuuYutbX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans=automl.predict(test.drop(['row_id'], axis=1))"
      ],
      "metadata": {
        "id": "cWP9xJTuuty_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['energy']=ans"
      ],
      "metadata": {
        "id": "obHGB97lv8sC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[['row_id','energy']].to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "id": "qoOi81mEvL9T"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/sample_submission_jn0a7vR.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lqkMUNFlvEnc",
        "outputId": "fb97b258-f9fc-4b19-f1a5-86260a2d7b72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       row_id       energy\n",
              "0       94993  1702.995014\n",
              "1       94994  1702.995014\n",
              "2       94995  1702.995014\n",
              "3       94996  1702.995014\n",
              "4       94997  1702.995014\n",
              "...       ...          ...\n",
              "26299  121292  1702.995014\n",
              "26300  121293  1702.995014\n",
              "26301  121294  1702.995014\n",
              "26302  121295  1702.995014\n",
              "26303  121296  1702.995014\n",
              "\n",
              "[26304 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-025ca504-0a2e-4d47-9ccd-152caa611618\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>energy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>94993</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>94994</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94995</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94996</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94997</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26299</th>\n",
              "      <td>121292</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26300</th>\n",
              "      <td>121293</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26301</th>\n",
              "      <td>121294</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26302</th>\n",
              "      <td>121295</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26303</th>\n",
              "      <td>121296</td>\n",
              "      <td>1702.995014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26304 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-025ca504-0a2e-4d47-9ccd-152caa611618')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-025ca504-0a2e-4d47-9ccd-152caa611618 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-025ca504-0a2e-4d47-9ccd-152caa611618');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6loK4-Bjvddx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e811209110f5aa4d8c2189eeb3ff7b9b4d146931cb9189ef6041ff71605c541d"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}